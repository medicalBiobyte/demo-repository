import os
import pandas as pd
from dotenv import load_dotenv
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document


# ë¬¸ì„œ ë³€í™˜ í•¨ìˆ˜ë“¤
def fnclty_to_doc(row):
    return Document(
        page_content=f"{row.get('APLC_RAWMTRL_NM', '')} - {row.get('FNCLTY_CN', '')}",
        metadata={
            "source": "fnclty",
            "material": row.get("APLC_RAWMTRL_NM", ""),
            "functionality": row.get("FNCLTY_CN", ""),
            "intake": row.get("DAY_INTK_CN", ""),
            "caution": row.get("IFTKN_ATNT_MATR_CN", ""),
        },
    )


def drug_to_doc(row):
    return Document(
        page_content=f"{row.get('itemName', '')} - {row.get('efcyQesitm', '')}",
        metadata={
            "source": "drug",
            "product": row.get("itemName", ""),
            "manufacturer": row.get("entpName", ""),
            "efficacy": row.get("efcyQesitm", ""),
            "usage": row.get("useMethodQesitm", ""),
            "caution": row.get("atpnQesitm", ""),
        },
    )


def healthfood_claims_to_doc(row):
    if not row.get("ì œí’ˆëª…") or not row.get("ê¸°ëŠ¥ì„± ë‚´ìš©"):
        return None
    text = (
        f"ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ ì œí’ˆëª…: {row['ì œí’ˆëª…']}. ì£¼ìš” ê¸°ëŠ¥ì„± ë‚´ìš©: {row['ê¸°ëŠ¥ì„± ë‚´ìš©']}."
    )
    if row.get("ì¼ì¼ì„­ì·¨ëŸ‰"):
        text += f" ì¼ì¼ ì„­ì·¨ëŸ‰: {row['ì¼ì¼ì„­ì·¨ëŸ‰']}."
    if row.get("ì„­ì·¨ ì‹œ ì£¼ì˜ì‚¬í•­"):
        text += f" ì„­ì·¨ ì‹œ ì£¼ì˜ì‚¬í•­: {row['ì„­ì·¨ ì‹œ ì£¼ì˜ì‚¬í•­']}."
    return Document(
        page_content=text,
        metadata={
            "source": "healthfood_claims_final10",
            "product_name": row.get("ì œí’ˆëª…", ""),
            "functionality_content": row.get("ê¸°ëŠ¥ì„± ë‚´ìš©", ""),
            "daily_intake": row.get("ì¼ì¼ì„­ì·¨ëŸ‰", "ì •ë³´ ì—†ìŒ"),
            "precautions": row.get("ì„­ì·¨ ì‹œ ì£¼ì˜ì‚¬í•­", "ì •ë³´ ì—†ìŒ"),
            "original_filename": row.get("íŒŒì¼ëª…", ""),
        },
    )


# Main ì‹¤í–‰ë¶€
if __name__ == "__main__":
    print("ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë”© ì¤‘...")
    load_dotenv()
    os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
    print("âœ… OPENAI_API_KEY ë¡œë”© ì™„ë£Œ")

    fnclty_path = "csv_data/fnclty_materials_complete.csv"
    drug_path = "csv_data/drug_raw.csv"
    healthfood_claims_path = "csv_data/healthfood_claims_final10.csv"

    # CSV ë¡œë”©
    print(f"ğŸ“„ CSV íŒŒì¼ ë¡œë”© ì¤‘: {fnclty_path}")
    df_fnclty = pd.read_csv(fnclty_path)
    print(f"â¡ï¸ {len(df_fnclty)}ê°œì˜ ê¸°ëŠ¥ì„± ì„±ë¶„ ë¡œë”© ì™„ë£Œ")

    print(f"ğŸ“„ CSV íŒŒì¼ ë¡œë”© ì¤‘: {drug_path}")
    df_drug = pd.read_csv(drug_path)
    print(f"â¡ï¸ {len(df_drug)}ê°œì˜ ì˜ì•½í’ˆ ë°ì´í„° ë¡œë”© ì™„ë£Œ")

    print(f"ğŸ“„ CSV íŒŒì¼ ë¡œë”© ì¤‘: {healthfood_claims_path}")
    try:
        df_healthfood_claims = pd.read_csv(healthfood_claims_path)
        print(f"â¡ï¸ {len(df_healthfood_claims)}ê°œì˜ ê±´ê°•ê¸°ëŠ¥ì‹í’ˆ í´ë ˆì„ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: {healthfood_claims_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        df_healthfood_claims = pd.DataFrame()

    # ë¬¸ì„œ ë³€í™˜
    print("ğŸ“¦ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘...")
    docs_fnclty = [fnclty_to_doc(row) for _, row in df_fnclty.iterrows()]
    docs_drug = [drug_to_doc(row) for _, row in df_drug.iterrows()]
    docs_healthfood_claims = [
        doc
        for _, row in df_healthfood_claims.iterrows()
        if (doc := healthfood_claims_to_doc(row)) is not None
    ]
    all_docs = docs_fnclty + docs_drug + docs_healthfood_claims
    print(f"âœ… ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œ ë³€í™˜ ì™„ë£Œ")

    # ë²¡í„° DB ì´ˆê¸°í™”
    print("ğŸ”§ ë²¡í„° DB ì´ˆê¸°í™” ì¤‘...")
    embedding = OpenAIEmbeddings(model="text-embedding-3-small", dimensions=1536)
    vector_db = Chroma(
        persist_directory="./chroma_db",
        collection_name="health_collection",
        embedding_function=embedding,
    )
    print("âœ… ë²¡í„° DB ì´ˆê¸°í™” ì™„ë£Œ")

    # ë°°ì¹˜ ì €ì¥
    print(f"ğŸ“¤ ì´ {len(all_docs)}ê°œ ë¬¸ì„œ ì €ì¥ ì¤‘...")
    batch_size = 1000
    for i in range(0, len(all_docs), batch_size):
        batch = all_docs[i : i + batch_size]
        try:
            print(f"â¡ï¸ ì €ì¥ ì¤‘: ë¬¸ì„œ {i + 1} ~ {i + len(batch)}")
            vector_db.add_documents(batch)
        except Exception as e:
            print(f"âŒ ë°°ì¹˜ ì €ì¥ ì‹¤íŒ¨ (index {i}): {e}")
            break
    else:
        print("ğŸ‰ ëª¨ë“  ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")

    # ì €ì¥ëœ ë¬¸ì„œ ìˆ˜ í™•ì¸
    try:
        if vector_db._collection:
            print(f"âœ¨ ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {vector_db._collection.count()}")
    except Exception as e:
        print(f"âš ï¸ ë¬¸ì„œ ìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
