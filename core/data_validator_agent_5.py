import json
from typing import Dict, Any, Optional, List

from .state_types import GraphState
from .config import text_llm
from .prompt import DATA_VALIDATION_PROMPT
from .utils import extract_json_string, save_step_output


def node_validate_data_consistency(state: GraphState) -> Dict[str, Any]:
    if state.get("error_message") and state.get("current_step") != "evaluate_product": # ì´ì „ ë‹¨ê³„ ì—ëŸ¬ ì‹œ ìŠ¤í‚µ (í‰ê°€ í›„ì—ëŠ” ì‹¤í–‰)
        return {}
    state["current_step"] = "validate_data_consistency"
    print(f"--- ğŸƒ ë‹¨ê³„ ì‹¤í–‰: {state['current_step']} ---")

    image_data = state.get("image_data", {})
    evaluation_result = state.get("evaluation_result", {}) # claim_check_3.pyì˜ ê²°ê³¼

    product_name = image_data.get("ì œí’ˆëª…", evaluation_result.get("ì œí’ˆëª…", "ì•Œ ìˆ˜ ì—†ìŒ"))
    image_claims_list = image_data.get("íš¨ëŠ¥_ì£¼ì¥", [])

    # evaluation_resultì—ì„œ ì •ë³´ ì¶”ì¶œ
    # claim_check_3.py ë° rag_service_3_1.pyì˜ ì¶œë ¥ êµ¬ì¡°ë¥¼ ì°¸ì¡°í•©ë‹ˆë‹¤.
    ingredients_from_web_db = evaluation_result.get("í™•ì •_ì„±ë¶„", [])
    matched_ingredients_eval_raw = evaluation_result.get("ë§¤ì¹­_ì„±ë¶„", []) # claim_check_3
    rag_based_eval_raw = evaluation_result.get("RAG_ë³´ì™„", {}).get("ì„±ë¶„_ê¸°ë°˜_í‰ê°€", []) # rag_service_3_1

    # í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
    def format_eval(eval_list):
        return "\n".join([f"- {item.get('ì„±ë¶„ëª…')}: {item.get('íš¨ëŠ¥')} (ì¼ì¹˜ë„: {item.get('ì¼ì¹˜ë„')}, ì¶œì²˜: {item.get('ì¶œì²˜', 'DB/ì›¹')})" for item in eval_list if item.get('ì„±ë¶„ëª…')])

    matched_ingredients_eval_str = format_eval(matched_ingredients_eval_raw)
    rag_based_eval_str = format_eval(rag_based_eval_raw)
    user_query_keywords = evaluation_result.get("ì§ˆë¬¸_í•µì‹¬_í‚¤ì›Œë“œ", []) # claim_check_3

    prompt = DATA_VALIDATION_PROMPT.format(
        product_name_from_image=product_name,
        image_claims_list=str(image_claims_list),
        ingredients_from_web_db=str(ingredients_from_web_db),
        matched_ingredients_eval=matched_ingredients_eval_str if matched_ingredients_eval_str else "ì •ë³´ ì—†ìŒ",
        rag_based_eval=rag_based_eval_str if rag_based_eval_str else "ì •ë³´ ì—†ìŒ",
        user_query_keywords=str(user_query_keywords)
    )

    try:
        response = text_llm.invoke(prompt)
        raw_text = response.content # LLMì˜ ì›ë³¸ ì‘ë‹µ í…ìŠ¤íŠ¸

        # â— JSON íŒŒì‹± ì „ì— Markdown ì½”ë“œ ë¸”ë¡ ì œê±°
        cleaned_json_text = extract_json_string(raw_text)
        # ì •ì œëœ í…ìŠ¤íŠ¸ë¡œ JSON íŒŒì‹±
        parsed_response = json.loads(cleaned_json_text)

        consistency_status = parsed_response.get("consistency_status", "ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ íŒë‹¨ ì–´ë ¤ì›€")
        validation_details = parsed_response.get("validation_details", [])
        overall_assessment = parsed_response.get("overall_assessment", "") # overall_assessmentë„ ê°€ì ¸ì˜¤ë„ë¡ ì¶”ê°€

        print(f"ğŸ“Š ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ ê²°ê³¼: {consistency_status}")
        if validation_details:
            for detail in validation_details:
                if not detail.get("evidence_found"):
                    print(f"  âš ï¸ ì£¼ì¥ ë¶ˆì¼ì¹˜/ê·¼ê±° ë¶€ì¡±: '{detail.get('claim')}' - {detail.get('discrepancy_note')}")

        output = {
            "data_consistency_status": consistency_status,
            "validation_issues": validation_details,
            "error_message": None
        }
        
        if state.get("evaluation_result"):
            current_eval_result = state["evaluation_result"].copy() # ë³µì‚¬ë³¸ ì‚¬ìš© ê¶Œì¥
            current_eval_result["data_validation_summary"] = {
                "status": consistency_status,
                "issues": validation_details,
                "assessment_comment": overall_assessment # íŒŒì‹±í•œ overall_assessment ì‚¬ìš©
            }
            # output ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ê±°ë‚˜, ë°˜í™˜ ì‹œ í•©ì¹˜ëŠ” ëŒ€ì‹ ,
            # GraphStateì˜ í‚¤ì— ì§ì ‘ í• ë‹¹í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            # ì—¬ê¸°ì„œëŠ” evaluation_resultë¥¼ ì—…ë°ì´íŠ¸í•˜ê³ , outputì—ëŠ” validation_issues ë“±ë§Œ í¬í•¨
            return {
                "evaluation_result": current_eval_result, 
                "data_consistency_status": consistency_status, # GraphState í•„ë“œì— ì§ì ‘ ë§¤í•‘ë˜ë„ë¡
                "validation_issues": validation_details,       # GraphState í•„ë“œì— ì§ì ‘ ë§¤í•‘ë˜ë„ë¡
                "error_message": None
            }

        # evaluation_resultê°€ ì—†ëŠ” ê²½ìš° (ì´ë¡ ì ìœ¼ë¡œëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ì±„ì›Œì ¸ì•¼ í•¨)
        return output

    except json.JSONDecodeError as e:
        # â— ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ì‘ë‹µ(raw_text)ê³¼ ì •ì œ ì‹œë„í•œ í…ìŠ¤íŠ¸(cleaned_json_text)ë¥¼ í•¨ê»˜ ë¡œê¹…í•˜ë©´ ë””ë²„ê¹…ì— ë„ì›€
        cleaned_text_for_log = cleaned_json_text if 'cleaned_json_text' in locals() else "ì •ì œ ì „ ë˜ëŠ” ì •ì œ ì‹¤íŒ¨"
        error_msg = f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë³¸ ì‘ë‹µ: {raw_text if 'raw_text' in locals() else 'ì‘ë‹µ ì—†ìŒ'}. ì •ì œ ì‹œë„í•œ í…ìŠ¤íŠ¸: {cleaned_text_for_log}"
        print(f"âŒ {state['current_step']} ì˜¤ë¥˜: {error_msg}")
        return {"error_message": error_msg} # GraphStateì˜ error_message í•„ë“œì— ì§ì ‘ í• ë‹¹ë¨
    except Exception as e:
        error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ ({type(e).__name__}): {e}"
        print(f"âŒ {state['current_step']} ì˜¤ë¥˜: {error_msg}")
        return {"error_message": error_msg}