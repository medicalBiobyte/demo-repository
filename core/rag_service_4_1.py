import os
import json
from datetime import datetime
from core.prompt import QUERY2KEYWORD_PROMPT
from core.config import vector_store, text_llm
from langchain.schema import Document  # ë°˜ë“œì‹œ í¬í•¨
import cohere

SAVE_DIR = "RAG_RESULTS"
os.makedirs(SAVE_DIR, exist_ok=True)
# ğŸ§  Cohere Reranker ì„¤ì •
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
cohere_client = cohere.Client(COHERE_API_KEY)


# ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords(query: str) -> list[str]:
    prompt = QUERY2KEYWORD_PROMPT.replace("{query}", query)
    response = text_llm.invoke(prompt)
    try:
        return json.loads(response.content)
    except Exception as e:
        print("âŒ í‚¤ì›Œë“œ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        print("ì›ë¬¸:", response.content)
        return []


def decide_final_judgment(user_query: str, evaluation_results: list[dict]) -> str:
    formatted_result = "\n".join(
        [
            f"- ì„±ë¶„: {item['ì„±ë¶„ëª…']}\n  íš¨ëŠ¥ ìš”ì•½: {item['íš¨ëŠ¥']}\n  ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì¼ì¹˜ë„: {item['ì¼ì¹˜ë„']}"
            for item in evaluation_results
        ]
    )
    prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ê±´ê°• ê¸°ëŠ¥ì‹í’ˆ ê´€ë ¨ ì§ˆë¬¸ê³¼ ê·¸ì— ëŒ€í•œ ì„±ë¶„ë³„ ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.

ì§ˆë¬¸: "{user_query}"

ì„±ë¶„ë³„ í‰ê°€ ê²°ê³¼:
{formatted_result}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ì œí’ˆì˜ ê´‘ê³  ì£¼ì¥ì´ ê³¼í•™ì ìœ¼ë¡œ ì¶©ë¶„íˆ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•´ ì£¼ì„¸ìš”.
ê²°ë¡ ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

ìµœì¢… íŒë‹¨:"""

    try:
        decision_response = text_llm.invoke(prompt)
        return decision_response.content.strip()
    except Exception as e:
        print(f"âŒ LLM íŒë‹¨ ì˜¤ë¥˜: {e}")
        return "íŒë‹¨ ì‹¤íŒ¨: ì˜¤ë¥˜ ë°œìƒ"


def cohere_rerank(query: str, docs: list[Document], top_n: int = 5) -> list[Document]:
    contents = [doc.page_content for doc in docs]
    response = cohere_client.rerank(
        query=query, documents=contents, top_n=top_n, model="rerank-multilingual-v3.0"
    )
    reranked = [docs[result.index] for result in response.results]
    return reranked


def run_rag_from_ingredients(
    enriched_info: dict, user_query: str, strategy: str = "mmr", save: bool = True
) -> dict:
    keywords = extract_keywords(user_query)
    ingredients = enriched_info.get("ì„±ë¶„_íš¨ëŠ¥", [])

    retriever = vector_store.as_retriever(
        search_type=strategy,
        search_kwargs=(
            {"k": 10, "fetch_k": 20, "lambda_mult": 0.7}
            if strategy == "mmr"
            else {"k": 10}
        ),
    )

    evaluation_results = []
    seen_ingredients = set()  # âœ… ì¤‘ë³µ ë°©ì§€ìš© ì§‘í•©

    for item in ingredients:
        ingredient_name = item.get("ì„±ë¶„ëª…", "")
        if not ingredient_name or ingredient_name in seen_ingredients:
            continue
        seen_ingredients.add(ingredient_name)

        print(f"ğŸ§¬ RAG ê²€ìƒ‰ ì¤‘ (ì„±ë¶„: {ingredient_name})")
        retrieved_docs = retriever.invoke(ingredient_name)

        if not retrieved_docs:
            evaluation_results.append(
                {
                    "ì„±ë¶„ëª…": ingredient_name,
                    "íš¨ëŠ¥": "ì •ë³´ ì—†ìŒ",
                    "ì¼ì¹˜ë„": "ì •ë³´ ì—†ìŒ",
                    "ì¶œì²˜": ["ë¬¸ì„œ ì—†ìŒ"],
                }
            )
            continue

        # ğŸ” Rerank ì „ ì¶œë ¥
        print(f"ğŸ” [BEFORE RERANK] {ingredient_name} ê´€ë ¨ ì›ë³¸ ë¬¸ì„œ:")
        for i, doc in enumerate(retrieved_docs[:5]):
            preview = doc.page_content[:100].replace("\n", " ")
            print(f"  [{i+1}] {preview}...")

        # ğŸ’¡ Cohere Rerank ì ìš©
        reranked_docs = cohere_rerank(
            query=ingredient_name,
            docs=retrieved_docs,
            top_n=5,
        )

        # ğŸ† Rerank í›„ ì¶œë ¥
        print(f"ğŸ† [AFTER RERANK] {ingredient_name} ê´€ë ¨ ìƒìœ„ ë¬¸ì„œ:")
        for i, doc in enumerate(reranked_docs):
            preview = doc.page_content[:100].replace("\n", " ")
            print(f"  [{i+1}] {preview}...")

        # ğŸ“¦ ì¶œì²˜ ìˆ˜ì§‘
        sources = []
        for doc in reranked_docs:
            source = doc.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
            identity = (
                doc.metadata.get("material")
                or doc.metadata.get("product_name")
                or doc.metadata.get("product")
                or "N/A"
            )
            sources.append(f"{source} / {identity}")

        context = "\n\n---\n\n".join(
            [
                f"[ì¶œì²˜: {sources[i]}]\n{doc.page_content}"
                for i, doc in enumerate(reranked_docs)
            ]
        )

        prompt = f"""ë‹¤ìŒì€ '{ingredient_name}' ì„±ë¶„ê³¼ ê´€ë ¨ëœ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤.
ì´ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì£¼ìš” íš¨ëŠ¥ì„ í•œê¸€ë¡œ ê°„ê²°íˆ ìš”ì•½í•˜ì„¸ìš”.

[ë¬¸ì„œ ì‹œì‘]
{context}
[ë¬¸ì„œ ë]

íš¨ëŠ¥ ìš”ì•½:"""

        try:
            llm_response = text_llm.invoke(prompt)
            efficacy = llm_response.content.strip() or "ì •ë³´ ì—†ìŒ"
            match_status = (
                "ì¼ì¹˜"
                if any(kw in efficacy for kw in keywords)
                else "ë¶ˆì¼ì¹˜ ë˜ëŠ” ì§ì ‘ ê´€ë ¨ ì—†ìŒ"
            )
        except Exception as e:
            print(f"âŒ LLM ì˜¤ë¥˜: {e}")
            efficacy = "ì •ë³´ ì—†ìŒ"
            match_status = "ì •ë³´ ì—†ìŒ"

        evaluation_results.append(
            {
                "ì„±ë¶„ëª…": ingredient_name,
                "íš¨ëŠ¥": efficacy,
                "ì¼ì¹˜ë„": match_status,
                "ì¶œì²˜": sources[:3],
                "ì›ë³¸ë¬¸ì„œ": [doc.page_content for doc in retrieved_docs[:5]],
                "ì¬ì •ë ¬ë¬¸ì„œ": [doc.page_content for doc in reranked_docs],
            }
        )

    final_decision = decide_final_judgment(user_query, evaluation_results)

    result = {
        "ì§ˆë¬¸": user_query,
        "ì§ˆë¬¸_í‚¤ì›Œë“œ": keywords,
        "ì„±ë¶„_ê¸°ë°˜_í‰ê°€": evaluation_results,
        "ìµœì¢…_íŒë‹¨": final_decision,
    }

    if save:
        filename = f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAG_RERANK_RESULT.json"
        filepath = os.path.join(SAVE_DIR, filename)
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")

    return result


# ğŸ§ª ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    from core.web_search_3 import get_enriched_product_info

    print("ğŸ§ª RAG ì„œë¹„ìŠ¤ ì§ì ‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ ğŸ§ª")
    print("=" * 50)

    print("\n[í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 1: 'ë°€í¬ì”¨ìŠ¬(ì‹¤ë¦¬ë§ˆë¦°)' ì„±ë¶„ìœ¼ë¡œ RAG ê²€ìƒ‰]")

    test_user_query_for_milk_thistle = (
        "ë°€í¬ì”¨ìŠ¬ì´ ê°„ ê±´ê°•ì— ì–´ë–¤ íš¨ê³¼ê°€ ìˆë‚˜ìš”? ê´‘ê³ ì²˜ëŸ¼ ì •ë§ ì¢‹ì€ê°€ìš”?"
    )

    mock_enriched_info_milk_thistle = {
        "ì œí’ˆëª…": "ê°€ìƒ ë°€í¬ì”¨ìŠ¬ ì œí’ˆ",
        "ì„±ë¶„_íš¨ëŠ¥": [
            {
                "ì„±ë¶„ëª…": "ë°€í¬ì”¨ìŠ¬(ì‹¤ë¦¬ë§ˆë¦°)",
                "íš¨ëŠ¥": "ê°„ ê±´ê°• ê°œì„  (ì›¹ ì •ë³´ ê°€ì •)",
                "ì¶œì²˜": "ê°€ìƒ ì›¹ì‚¬ì´íŠ¸",
            },
        ],
        "í™•ì •_ì„±ë¶„": ["ë°€í¬ì”¨ìŠ¬(ì‹¤ë¦¬ë§ˆë¦°)"],
        "ìš”ì•½": "ì´ê²ƒì€ 'ë°€í¬ì”¨ìŠ¬(ì‹¤ë¦¬ë§ˆë¦°)' ì„±ë¶„ì˜ RAG ê²€ìƒ‰ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ ê°€ìƒ ì œí’ˆ ì •ë³´ì…ë‹ˆë‹¤.",
    }

    print(f"ì‚¬ìš©ì ì§ˆë¬¸: {test_user_query_for_milk_thistle}")
    print(
        f"ì…ë ¥ enriched_infoì˜ ì„±ë¶„: {[item['ì„±ë¶„ëª…'] for item in mock_enriched_info_milk_thistle.get('ì„±ë¶„_íš¨ëŠ¥', [])]}"
    )

    rag_result_milk_thistle = run_rag_from_ingredients(
        enriched_info=mock_enriched_info_milk_thistle,
        user_query=test_user_query_for_milk_thistle,
        save=False,
    )

    print("\n--- RAG ê²°ê³¼ (ë°€í¬ì”¨ìŠ¬ ì‹œë‚˜ë¦¬ì˜¤) ---")
    print(json.dumps(rag_result_milk_thistle, ensure_ascii=False, indent=2))
    print("-" * 50)
