import json
from typing import Dict, Any, Optional
from .state_types import GraphState
from .config import text_llm
from .prompt import INTENT_REFINEMENT_PROMPT
from .utils import extract_json_string, save_step_output

def node_refine_user_intent(state: GraphState) -> Dict[str, Any]:
    run_id = state.get("run_id") # run_id ê°€ì ¸ì˜¤ê¸°
    current_step_name = "refine_user_intent"

    print(f"--- ğŸƒ [{run_id}] ë‹¨ê³„ ì‹¤í–‰: {current_step_name} ---") # ë¡œê·¸ì— run_id ì¶”ê°€

    user_query = state["user_query"]
    product_name = state.get("product_name_from_image", "ì•Œ ìˆ˜ ì—†ëŠ” ì œí’ˆ")
    image_data = state.get("image_data", {})
    image_claims = image_data.get("íš¨ëŠ¥_ì£¼ì¥", [])

    # ì´ ë‹¨ê³„ì˜ ì…ë ¥ìœ¼ë¡œ ì €ì¥ë  ì •ë³´ ì •ì˜
    step_inputs_for_saving = {
        "user_query": user_query,
        "product_name_from_image": product_name,
        "image_claims": image_claims
    }

    node_return_output: Dict[str, Any] # ë…¸ë“œê°€ ë°˜í™˜í•  ìµœì¢… ë”•ì…”ë„ˆë¦¬
    status_for_saving = "success"      # ì €ì¥ë  ë‹¨ê³„ ì‹¤í–‰ ìƒíƒœ
    error_for_saving = None            # ì €ì¥ë  ì˜¤ë¥˜ ë©”ì‹œì§€

    try:
        image_claims_example = ", ".join(image_claims[:2]) + (" ë“±" if len(image_claims) > 2 else "")

        prompt = INTENT_REFINEMENT_PROMPT.format(
            user_query=user_query,
            product_name=product_name,
            image_claims=str(image_claims),
            image_claims_example=image_claims_example
        )

        response_from_llm = text_llm.invoke(prompt) # ë³€ìˆ˜ëª… ë³€ê²½ (response -> response_from_llm)
        raw_text = response_from_llm.content

        cleaned_json_text = extract_json_string(raw_text)
        parsed_response = json.loads(cleaned_json_text)

        is_ambiguous = parsed_response.get("is_ambiguous", True)
        inferred_query = parsed_response.get("inferred_query")
        confidence = parsed_response.get("confidence_level", "ì •ë³´ ì—†ìŒ")
        reasoning = parsed_response.get("reasoning", "ì •ë³´ ì—†ìŒ")

        query_for_processing: str
        if not inferred_query:
            print(f"âš ï¸ [{run_id}] LLMì´ 'inferred_query'ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ ì§ˆë¬¸ '{user_query}'ì„(ë¥¼) ë‚´ë¶€ ì²˜ë¦¬ìš©ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            query_for_processing = user_query
            is_ambiguous = True
        else:
            query_for_processing = inferred_query

        # â—€ï¸ ë¡œê·¸ì— run_id ì¶”ê°€
        if is_ambiguous:
            if query_for_processing != user_query :
                print(f"ğŸš¦ [{run_id}] ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸ '{user_query}'ì„(ë¥¼) ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì¬êµ¬ì„±í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                print(f"ğŸ¤– [{run_id}] ì¶”ë¡ ëœ ë‚´ë¶€ ì²˜ë¦¬ìš© ì§ˆë¬¸: '{query_for_processing}' (ì‹ ë¢°ë„: {confidence})")
                print(f"ğŸ¤” [{run_id}] ì¶”ë¡  ê·¼ê±°: {reasoning}")
            else:
                 print(f"ğŸš¦ [{run_id}] ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸ '{user_query}'ì€(ëŠ”) ëª¨í˜¸í•˜ì§€ë§Œ, ë‚´ë¶€ ì²˜ë¦¬ ì‹œ ì›ë³¸ ì§ˆë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì¶”ë¡ ëœ ì§ˆë¬¸: '{query_for_processing}', ì‹ ë¢°ë„: {confidence})")
                 if reasoning != "ì •ë³´ ì—†ìŒ": print(f"ğŸ¤” [{run_id}] ì°¸ê³  ê·¼ê±°: {reasoning}")
        else:
            print(f"ğŸ‘ [{run_id}] ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸ '{user_query}'ì„(ë¥¼) ê¸°ë°˜ìœ¼ë¡œ ë‚´ë¶€ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            if query_for_processing != user_query:
                print(f"âš™ï¸ [{run_id}] ë‚´ë¶€ ì²˜ë¦¬ìš© ì§ˆë¬¸ (ì•½ê°„ ìˆ˜ì •ë¨): '{query_for_processing}' (ì‹ ë¢°ë„: {confidence})")
                if reasoning != "ì •ë³´ ì—†ìŒ": print(f"ğŸ¤” [{run_id}] ì°¸ê³  ê·¼ê±°: {reasoning}")
            else:
                print(f"âš™ï¸ [{run_id}] ë‚´ë¶€ ì²˜ë¦¬ìš© ì§ˆë¬¸ì€ ì›ë³¸ê³¼ ë™ì¼í•©ë‹ˆë‹¤: '{query_for_processing}'")

        # ì„±ê³µ ì‹œ GraphState ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë°˜í™˜ê°’ êµ¬ì„±
        node_return_output = {
            "is_query_ambiguous": is_ambiguous,
            "refined_user_query": query_for_processing,
            "inferred_query_confidence": confidence, # GraphStateì— ì´ í•„ë“œë“¤ì´ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
            "inferred_query_reasoning": reasoning,   # GraphStateì— ì´ í•„ë“œë“¤ì´ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
            "error_message": None,
            "current_step": current_step_name
        }


    except json.JSONDecodeError as e:
        error_msg = f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì›ë³¸ ì‘ë‹µ: {response_from_llm.content if 'response_from_llm' in locals() else 'ì‘ë‹µ ì—†ìŒ'}"
        print(f"âŒ [{run_id}] {current_step_name} ì˜¤ë¥˜: {error_msg}")
        status_for_saving = "failure"
        error_for_saving = error_msg
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ GraphState ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë°˜í™˜ê°’ êµ¬ì„± (í•„ìˆ˜ í•„ë“œì— ê¸°ë³¸ê°’ ì œê³µ)
        node_return_output = {
            "error_message": error_msg,
            "refined_user_query": user_query, # ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            "is_query_ambiguous": True,       # ëª¨í˜¸í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
            "inferred_query_confidence": "ì˜¤ë¥˜",
            "inferred_query_reasoning": "JSON íŒŒì‹± ì˜¤ë¥˜",
            "current_step": current_step_name
        }
    except Exception as e:
        error_msg = f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ ({type(e).__name__}): {e}"
        print(f"âŒ [{run_id}] {current_step_name} ì˜¤ë¥˜: {error_msg}")
        status_for_saving = "failure"
        error_for_saving = error_msg
        # â—€ï¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ GraphState ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ë°˜í™˜ê°’ êµ¬ì„±
        node_return_output = {
            "error_message": error_msg,
            "refined_user_query": user_query, # ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´
            "is_query_ambiguous": True,       # ëª¨í˜¸í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
            "inferred_query_confidence": "ì˜¤ë¥˜",
            "inferred_query_reasoning": "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ",
            "current_step": current_step_name
        }

    # â—€ï¸ ê°œì„ ëœ save_step_output í•¨ìˆ˜ í˜¸ì¶œ (í•­ìƒ ì‹¤í–‰)
    save_step_output(
        run_id=run_id,
        step_name=current_step_name,
        step_inputs=step_inputs_for_saving,
        step_outputs=node_return_output, # ë…¸ë“œê°€ ë°˜í™˜í•˜ëŠ” ì „ì²´ ë‚´ìš©ì„ ì €ì¥
        status=status_for_saving,
        error_message=error_for_saving
    )

    return node_return_output