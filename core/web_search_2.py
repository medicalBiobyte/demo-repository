import os
import json
from dotenv import load_dotenv
from prompt import WEB2INGREDIENT_PROMPT  # ì•„ë˜ì—ì„œ ë§Œë“¤ í”„ë¡¬í”„íŠ¸
from config import web_search_llm, text_llm  # TavilyClient, ChatOpenAI
from typing import List
import re

# ğŸ“ ì„¤ì •
RESULT_ALL_PATH = "IMG2TEXT_data/result_all.json"
OUTPUT_DIR = "TEXT2SEARCH_data"
os.makedirs(OUTPUT_DIR, exist_ok=True)


# ğŸ” ê²€ìƒ‰ â†’ ìš”ì•½ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def search_product_and_summarize(product_name: str) -> str:
    search_result = web_search_llm.search(product_name + " ì„±ë¶„")  # or "ì„±ë¶„ íš¨ëŠ¥"
    results = search_result.get("results", [])

    content = ""
    for res in results:
        title = res.get("title", "")
        snippet = res.get("content", "")
        content += f"[{title}]\n{snippet}\n\n"

    return content.strip()


# ğŸ§  LLMì„ í†µí•´ ì„±ë¶„ + íš¨ëŠ¥ ì¶”ì¶œ
def extract_ingredients_and_effects(summary_text: str) -> dict:
    full_prompt = WEB2INGREDIENT_PROMPT.replace("{web_text}", summary_text)

    response = text_llm.invoke(full_prompt)
    raw_text = response.content

    def extract_json_string(text: str) -> str:
        match = re.search(r"```json(.*?)```", text, re.DOTALL)
        if match:
            return match.group(1).strip()
        return text.strip()

    cleaned = extract_json_string(raw_text)

    try:
        return json.loads(cleaned)
    except json.JSONDecodeError:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨\n", raw_text)
        return {}


# ğŸš€ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
def process_all_products():
    with open(RESULT_ALL_PATH, encoding="utf-8") as f:
        products = json.load(f)

    for entry in products:
        product_name = entry.get("ì œí’ˆëª…", "").split("/")[0].strip()
        if not product_name:
            continue

        print(f"ğŸ” ì›¹ ê²€ìƒ‰ ë° ì„±ë¶„ ì¶”ì¶œ ì¤‘: {product_name}")
        result_path = os.path.join(OUTPUT_DIR, f"enriched_{product_name}.json")

        if os.path.exists(result_path):
            print(f"âœ… ì´ë¯¸ ì²˜ë¦¬ë¨: {product_name}")
            continue

        # 1. ê²€ìƒ‰ + ìš”ì•½
        web_summary = search_product_and_summarize(product_name)

        # 2. ìš”ì•½ë¬¸ + í”„ë¡¬í”„íŠ¸ â†’ LLM ì²˜ë¦¬
        parsed_result = extract_ingredients_and_effects(web_summary)

        if parsed_result:
            parsed_result["ì œí’ˆëª…"] = product_name
            parsed_result["ìš”ì•½_í…ìŠ¤íŠ¸"] = web_summary  # Optional: ì¶œì²˜ ê¸°ë¡ìš©

            with open(result_path, "w", encoding="utf-8") as f:
                json.dump(parsed_result, f, ensure_ascii=False, indent=2)

            print(f"âœ… ì €ì¥ ì™„ë£Œ: {result_path}")
        else:
            print(f"âš ï¸ ì‹¤íŒ¨: {product_name}")


if __name__ == "__main__":
    process_all_products()
